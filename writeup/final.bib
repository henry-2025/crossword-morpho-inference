@InProceedings{Angelini05-Webcrow,
author="Angelini, Giovanni
and Ernandes, Marco
and Gori, Marco",
editor="Maybury, Mark
and Stock, Oliviero
and Wahlster, Wolfgang",
title="Webcrow: A Web-Based Crosswords Solver",
booktitle="Intelligent Technologies for Interactive Entertainment",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="295--298"
}

@inproceedings{Tsochantaridis04-Support,
  title={Support vector machine learning for interdependent and structured output spaces},
  author={Tsochantaridis, Ioannis and Hofmann, Thomas and Joachims, Thorsten and Altun, Yasemin},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={104},
  year={2004}
}

@ARTICLE{Littman02-AProbabilistic,
    author = {Michael L. Littman and Greg A. Keim and Noam Shazeer},
    title = {A probabilistic approach to solving crossword puzzles},
    journal = {ARTIF. INTELL},
    year = {2002},
    volume = {134}
}

@inproceedings{Keim99-PROVERB,
  title={PROVERB: The Probabilistic Cruciverbalist},
  author={Greg A. Keim and Noam M. Shazeer and Michael L. Littman and Sushant Agarwal and Catherine M. Cheves and Joseph Fitzgerald and Jason Grosland and Fan Jiang and Shannon Pollard and Karl Weinmeister},
  booktitle={AAAI/IAAI},
  year={1999}
}

@inproceedings{Shazeer99-Solving,
author = {Shazeer, Noam M. and Littman, Michael L. and Keim, Greg A.},
title = {Solving Crossword Puzzles as Probabilistic Constraint Satisfaction},
year = {1999},
isbn = {0262511061},
publisher = {American Association for Artificial Intelligence},
address = {USA},
abstract = {Crossword puzzle solving is a classic constraint satisfaction problem, but, when solving a real puzzle, the mapping from clues to variable domains is not perfectly crisp. At best, clues induce a probability distribution over viable targets, which must somehow be respected along with the constraints of the puzzle. Motivated by this type of problem, we describe a formal model of constraint satisfaction with probabilistic preferences on variable values. Two natural optimization problems are defined for this model: maximizing the probability of a correct solution, and maximizing the number of correct words (variable values) in the solution. To the latter, we apply an efficient iterative approximation equivalent to turbo decoding and present results on a collection of real and artificial crossword puzzles.},
booktitle = {Proceedings of the Sixteenth National Conference on Artificial Intelligence and the Eleventh Innovative Applications of Artificial Intelligence Conference Innovative Applications of Artificial Intelligence},
pages = {156–162},
numpages = {7},
location = {Orlando, Florida, USA},
series = {AAAI '99/IAAI '99}
}

% DR FILL
@article{Ginsberg11-DrFill,
author = {Ginsberg, Matthew L.},
title = {DR.FILL: Crosswords and an Implemented Solver for Singly Weighted CSPs},
year = {2011},
issue_date = {September 2011},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {42},
number = {1},
issn = {1076-9757},
abstract = {We describe Dr. Fill, a program that solves American-style crossword puzzles. From a technical perspective, Dr. Fill works by converting crosswords to weighted csps, and then using a variety of novel techniques to find a solution. These techniques include generally applicable heuristics for variable and value selection, a variant of limited discrepancy search, and postprocessing and partitioning ideas. Branch and bound is not used, as it was incompatible with postprocessing and was determined experimentally to be of little practical value. Dr. Fill's performance on crosswords from the American Crossword Puzzle Tournament suggests that it ranks among the top fifty or so crossword solvers in the world.},
journal = {J. Artif. Int. Res.},
month = {sep},
pages = {851–886},
numpages = {36}
}

% treetagger
@Inbook{Schmid95-Improvements,
author="Schmid, H.",
title="Improvements in Part-of-Speech Tagging with an Application to German",
bookTitle="Natural Language Processing Using Very Large Corpora",
year="1999",
publisher="Springer Netherlands",
address="Dordrecht",
pages="13--25",
abstract="Work on part-of-speech tagging has concentrated on English in the past, since a lot of manually tagged training material is available for English and results can be compared to those of other researchers. It was assumed that methods which have been developed for English would work for other languages as well.1",
isbn="978-94-017-2390-9",
doi="10.1007/978-94-017-2390-9_2",
url="https://doi.org/10.1007/978-94-017-2390-9_2"
}

% BERT
@article{Devlin18-BERT,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  eprinttype = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Mikolov13-word2vec,
  doi = {10.48550/ARXIV.1301.3781},
  url = {https://arxiv.org/abs/1301.3781},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Marcus93-penntreebank,
author = {Marcus, Mitchell P. and Marcinkiewicz, Mary Ann and Santorini, Beatrice},
title = {Building a Large Annotated Corpus of English: The Penn Treebank},
year = {1993},
issue_date = {June 1993},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {19},
number = {2},
issn = {0891-2017},
journal = {Comput. Linguist.},
month = {jun},
pages = {313–330},
numpages = {18}
}